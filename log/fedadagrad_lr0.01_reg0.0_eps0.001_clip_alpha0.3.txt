fedadagrad_training_loss [2.436302857513428, 2.4636083096313457, 2.4665548860168456, 3.14042048538208, 3.364297626495362, 3.337543295669556, 3.238137344284058, 2.733143010025025, 3.3410322704315187, 2.6468325247192377, 4.0521179993438725, 3.8125677477264395, 3.3126991468811027, 3.068191375122071, 3.2349622116851795, 2.816053091583251, 3.2918640067291256, 3.5042069384002694, 4.257665864105223, 3.1475032732391357, 2.231511718292237, 2.4800028810882555, 3.3547340317535412, 4.144058010406494, 3.77634954032898, 3.00719822784424, 2.888035618515015, 2.7984431620025636, 2.511723616027833, 2.8899833946228033, 3.0768829794311525, 2.2518305030059813, 2.5932845384216296, 3.1167800189209003]
fedadagrad_training_accuracy [10.00000000178814, 18.6360000140965, 13.722000022232532, 11.075999904572964, 14.204000070691109, 14.25199999704957, 13.82600004658103, 15.621999952197076, 11.5960000243783, 12.135999977439642, 11.807999987751245, 10.036000039726495, 9.999999981224537, 19.391999990195036, 14.190000052005052, 18.407999973595143, 12.714000004231929, 10.150000012367963, 10.015999986976386, 10.10800006493926, 19.957999958992005, 18.972000118941068, 16.73000001847744, 10.000000052452087, 12.763999997526406, 15.493999921530484, 16.910000070631504, 14.86400008663535, 19.984000045061112, 18.75400003939867, 16.75800001785159, 23.769999984502793, 14.966000019609929, 15.641999941170216]
fedadagrad_test_loss [2.433081671142578, 2.462196657562256, 2.466376342010498, 3.1314690139770507, 3.363892608642578, 3.3385166717529295, 3.2331553329467773, 2.728651300048828, 3.3368544921875, 2.643777001953125, 4.05833024597168, 3.809734880065918, 3.3093872421264647, 3.0550516799926757, 3.243026248931885, 2.797135193634033, 3.299620945739746, 3.4829124465942383, 4.280579954528808, 3.1434910934448244, 2.2194966423034668, 2.457329995727539, 3.3375954849243166, 4.136510794067383, 3.748360639953613, 3.0067399353027344, 2.872560082244873, 2.7837007820129394, 2.512059979248047, 2.8586959495544435, 3.067990151977539, 2.244284860229492, 2.5837020698547364, 3.093887782287598]
fedadagrad_testing_accuracy [array(10., dtype=float32), array(19.16, dtype=float32), array(13.64, dtype=float32), array(11.13, dtype=float32), array(14.65, dtype=float32), array(14.09, dtype=float32), array(13.78, dtype=float32), array(15.47, dtype=float32), array(11.76, dtype=float32), array(11.84, dtype=float32), array(12.03, dtype=float32), array(10.11, dtype=float32), array(10., dtype=float32), array(19.26, dtype=float32), array(13.68, dtype=float32), array(19.14, dtype=float32), array(12.42, dtype=float32), array(10.14, dtype=float32), array(10.01, dtype=float32), array(10.13, dtype=float32), array(20.2, dtype=float32), array(19.38, dtype=float32), array(16.55, dtype=float32), array(10., dtype=float32), array(12.95, dtype=float32), array(15.8, dtype=float32), array(17.95, dtype=float32), array(15.07, dtype=float32), array(20.29, dtype=float32), array(18.72, dtype=float32), array(16.75, dtype=float32), array(24.14, dtype=float32), array(15.02, dtype=float32), array(15.96, dtype=float32)]
fedadagrad_global_learning_rate [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
