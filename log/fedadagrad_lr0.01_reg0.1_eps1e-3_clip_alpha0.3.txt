fedadagrad_training_loss [2.6564678646850592, 27.56711256347655, 9.946981460571287, 2.6145601902771, 2.3325043757629396, 2.3166995370483385, 2.3094064781188965, 2.5768084030151357, 10.192492664566041, 21.58234625793458, 6.972475814056395, 2.3141331365966793]
fedadagrad_training_accuracy [12.709999988228082, 10.000000052452087, 9.999999981224537, 10.000000016093255, 10.000000030845404, 10.000000046342612, 10.00000000178814, 10.000000044703484, 9.99999999806285, 9.999999981224537, 10.000000016093255, 10.00000000178814]
fedadagrad_test_loss [2.6520278854370116, 27.546915270996095, 9.87063489074707, 2.6132210144042967, 2.332489051055908, 2.316701103210449, 2.3094073554992676, 2.5768125480651856, 10.192494064331054, 21.582339208984376, 6.9724763519287105, 2.3141331398010254]
fedadagrad_testing_accuracy [array(13.06, dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32), array(10., dtype=float32)]
fedadagrad_global_learning_rate [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
