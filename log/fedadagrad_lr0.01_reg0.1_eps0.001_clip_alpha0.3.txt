fedadagrad_training_loss [2.4529906376647954, 2.479904026260377, 2.501828086090087, 2.8601967856597894, 3.379461582260132, 2.9964803174591066, 3.0491294937896747, 2.9076056490325923, 2.9375920030212397, 2.7530977828979495, 3.8367784843444808, 3.1612964452362053, 3.6028952109527577, 3.0091980636596696, 3.023251840820313, 2.6541549491882335, 3.396475476608277, 2.979895516891479, 3.3878504817962636, 3.119007383346558, 2.7488535433197017, 2.7102384519195564, 2.460107187957764, 3.37476484336853, 2.8335070967102043, 2.7536492198181164, 2.857614760818481, 2.6165276959228523, 2.651598358688355, 3.17677088218689, 2.670161321029663, 2.425753860321046]
fedadagrad_training_accuracy [10.006000012308359, 17.75200007557869, 12.312000052034854, 12.748000027835369, 10.000000044703484, 15.115999952107668, 14.204000092297793, 13.40799998253584, 12.268000030964613, 12.395999917834997, 12.03999994367361, 10.020000020563602, 10.094000018388034, 11.929999998360872, 15.040000007599593, 14.391999950259924, 13.10799997702241, 10.579999977648258, 10.062000032663345, 10.216000071913005, 11.824000034481287, 12.256000101417303, 19.247999938130377, 10.000000052452087, 12.378000034242868, 17.199999969154597, 16.10799993529916, 21.0439999820292, 16.72000003352761, 15.053999889940023, 16.895999989807606, 13.113999954611064]
fedadagrad_test_loss [2.449396078491211, 2.480267948150635, 2.501540743255615, 2.8543116203308108, 3.379938850402832, 2.9983437187194824, 3.0492378479003905, 2.9085791259765625, 2.945270497894287, 2.752152603149414, 3.836564337158203, 3.154841537475586, 3.6104603485107423, 3.0081751251220705, 3.0185528289794923, 2.6484272323608398, 3.3952207275390625, 2.9746902275085447, 3.386124607849121, 3.1148647064208985, 2.7512014289855955, 2.710395220184326, 2.4469783149719238, 3.3816894958496095, 2.833756848144531, 2.7415946197509764, 2.8543640113830566, 2.595518976593018, 2.6587703353881835, 3.1509964447021486, 2.675637213897705, 2.4168833320617678]
fedadagrad_testing_accuracy [array(10., dtype=float32), array(17.9, dtype=float32), array(12.66, dtype=float32), array(12.75, dtype=float32), array(10., dtype=float32), array(14.97, dtype=float32), array(14.28, dtype=float32), array(13.08, dtype=float32), array(12.1, dtype=float32), array(12.47, dtype=float32), array(12.31, dtype=float32), array(10.09, dtype=float32), array(10.13, dtype=float32), array(11.69, dtype=float32), array(16.05, dtype=float32), array(15.42, dtype=float32), array(13.46, dtype=float32), array(10.59, dtype=float32), array(10.06, dtype=float32), array(10.23, dtype=float32), array(11.78, dtype=float32), array(11.94, dtype=float32), array(18.98, dtype=float32), array(10., dtype=float32), array(12.24, dtype=float32), array(17.25, dtype=float32), array(15.92, dtype=float32), array(21.39, dtype=float32), array(16.48, dtype=float32), array(15.56, dtype=float32), array(16.58, dtype=float32), array(13.36, dtype=float32)]
fedadagrad_global_learning_rate [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
